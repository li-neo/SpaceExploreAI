import os
import sys
import torch
import numpy as np
import pandas as pd
import argparse
from typing import Dict, List, Tuple, Optional, Union
from datetime import datetime, timedelta
from log.logger import get_logger
import logging
import math

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥é¡¹ç›®å†…æ¨¡å—
from model.transformer import StockPricePredictor
from data.download_data import download_yahoo_finance_data
from data.process_downloaded_data import DataArgs, process_specific_stocks
from train.model_args import ModelArgs

# è®¾ç½®æ—¥å¿—
logger = get_logger(__name__, log_file="inference.log")

class StockPredictor:
    """è‚¡ç¥¨ä»·æ ¼é¢„æµ‹å™¨ï¼Œç”¨äºå®æ—¶æ¨ç†"""
    
    def __init__(
        self, 
        model_path: str = "models/SpaceExploreAI_best.pt",
        device: str = None,
        feature_groups: List[str] = ['time', 'lag', 'return', 'volatility', 'volume'],
        sequence_length: int = 32,
        prediction_horizon: int = 2,
        raw_data_dir: str = "data/raw",
        processed_data_dir: str = "data/processed/inference",
        scaler_type: str = "robust"
    ):
        """
        åˆå§‹åŒ–è‚¡ç¥¨é¢„æµ‹å™¨
        
        å‚æ•°:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            device: è¿è¡Œè®¾å¤‡
            feature_groups: ç‰¹å¾ç»„
            sequence_length: åºåˆ—é•¿åº¦
            prediction_horizon: é¢„æµ‹å‘¨æœŸ
            raw_data_dir: åŸå§‹æ•°æ®ç›®å½•
            processed_data_dir: å¤„ç†åæ•°æ®ç›®å½•
            scaler_type: ç¼©æ”¾å™¨ç±»å‹
        """
        self.model_path = model_path
        self.device = device if device is not None else (
            "cuda" if torch.cuda.is_available() else 
            "mps" if torch.backends.mps.is_available() else 
            "cpu"
        )
        self.feature_groups = feature_groups
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
        self.raw_data_dir = raw_data_dir
        self.processed_data_dir = processed_data_dir
        self.scaler_type = scaler_type
        self.model = None
        self.logger = logger  # ä½¿ç”¨å…¨å±€çš„logger
        
        # åˆ›å»ºç›®å½•
        os.makedirs(self.raw_data_dir, exist_ok=True)
        os.makedirs(self.processed_data_dir, exist_ok=True)
        
        self.logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        self._load_model()
        
    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        self.logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
        try:
            self.predictor = StockPricePredictor.load(self.model_path, device=self.device)
            self.logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            raise
    
    def _download_latest_data(self, ticker: str, lookback_days: int = 180, interval: str = "1d") -> bool:
        """
        ä¸‹è½½æœ€æ–°çš„è‚¡ç¥¨æ•°æ®
        
        å‚æ•°:
            ticker: è‚¡ç¥¨ä»£ç 
            lookback_days: å›æº¯å¤©æ•°
            interval: æ•°æ®é—´éš”
            
        è¿”å›:
            æ˜¯å¦æˆåŠŸä¸‹è½½
        """
        self.logger.info(f"ä¸‹è½½è‚¡ç¥¨ {ticker} çš„æœ€æ–°æ•°æ®")
        
        # è®¡ç®—å¼€å§‹æ—¥æœŸ
        end_date = datetime.now().strftime("%Y-%m-%d")
        start_date = (datetime.now() - timedelta(days=lookback_days)).strftime("%Y-%m-%d")
        
        # è°ƒç”¨ä¸‹è½½å‡½æ•°
        return download_yahoo_finance_data(
            ticker=ticker,
            start_date=start_date,
            end_date=end_date,
            output_dir=self.raw_data_dir,
            interval=interval
        )
    
    def _process_data(self, ticker: str) -> Optional[np.ndarray]:
        """
        å¤„ç†è‚¡ç¥¨æ•°æ®
        
        å‚æ•°:
            ticker: è‚¡ç¥¨ä»£ç 
            
        è¿”å›:
            å¤„ç†åçš„ç‰¹å¾æ•°æ®ï¼Œå¦‚æœå¤„ç†å¤±è´¥åˆ™è¿”å›None
        """
        self.logger.info(f"å¤„ç†è‚¡ç¥¨ {ticker} çš„æ•°æ®")
        
        try:
            # å¤„ç†ç‰¹å®šè‚¡ç¥¨æ•°æ®
            results = process_specific_stocks(
                tickers=[ticker],
                raw_data_dir=self.raw_data_dir,
                processed_data_dir=self.processed_data_dir,
                test_size=0.0,  # ä¸éœ€è¦åˆ†å‰²æ•°æ®
                val_size=0.0,   # ä¸éœ€è¦åˆ†å‰²æ•°æ®
                sequence_length=self.sequence_length,
                prediction_horizon=self.prediction_horizon,
                feature_groups=self.feature_groups,
                scaler_type=self.scaler_type
            )
            
            if ticker not in results:
                self.logger.error(f"å¤„ç†è‚¡ç¥¨ {ticker} æ•°æ®å¤±è´¥")
                return None
                
            # è·å–å¤„ç†åçš„åºåˆ—
            sequences = results[ticker]['sequences']
            
            # ç¡®ä¿ç»´åº¦ä¸€è‡´
            feature_dim = sequences['train'][0].shape[-1]
            if feature_dim != 64:
                self.logger.warning(f"ç‰¹å¾ç»´åº¦ {feature_dim} ä¸é¢„æœŸçš„ 64 ä¸ä¸€è‡´ï¼Œå¯èƒ½å½±å“æ¨¡å‹æ€§èƒ½")
            
            # ä¿å­˜è®­ç»ƒæ•°æ®åˆ°ç£ç›˜ä»¥ä¾¿ç¨ååŠ è½½
            X_train = sequences['train'][0]
            y_train = sequences['train'][1]
            
            X_path = os.path.join(self.processed_data_dir, f"{ticker}_X_train.npy")
            y_path = os.path.join(self.processed_data_dir, f"{ticker}_y_train.npy")
            
            np.save(X_path, X_train)
            np.save(y_path, y_train)
            
            self.logger.info(f"å·²ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ° {X_path}")
            
            # è¿”å›æœ€æ–°åºåˆ—çš„ç‰¹å¾
            return X_train[-1:] 
        except Exception as e:
            self.logger.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def predict(self, ticker: str, inference_times: int = 10) -> Dict:
        """
        å¯¹å•ä¸ªè‚¡ç¥¨è¿›è¡Œé¢„æµ‹
        
        Args:
            ticker (str): è‚¡ç¥¨ä»£ç 
            inference_times (int): æ¨ç†æ¬¡æ•°ï¼Œé»˜è®¤ä¸º10
            
        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        try:
            # ä¸‹è½½æœ€æ–°æ•°æ®
            self.logger.info(f"ä¸‹è½½ {ticker} æœ€æ–°æ•°æ®...")
            self._download_latest_data(ticker)
            
            # å¤„ç†æ•°æ®
            self.logger.info(f"å¤„ç† {ticker} æ•°æ®...")
            features = self._process_data(ticker)
            if features is None:
                return {"ticker": ticker, "error": "å¤„ç†æ•°æ®å¤±è´¥"}
            
            # åŠ è½½å¤„ç†åçš„æ•°æ®
            self.logger.info(f"åŠ è½½ {ticker} å¤„ç†åçš„æ•°æ®...")
            X_path = os.path.join(self.processed_data_dir, f"{ticker}_X_train.npy")
            if not os.path.exists(X_path):
                return {"ticker": ticker, "error": "å¤„ç†åçš„æ•°æ®ä¸å­˜åœ¨"}
            
            X = np.load(X_path)
            if X.shape[0] == 0:
                return {"ticker": ticker, "error": "å¤„ç†åçš„æ•°æ®ä¸ºç©º"}
            
            # è·å–å½“å‰æ—¶é—´æˆ³
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # å¤šæ¬¡æ¨ç†å¹¶è®¡ç®—å¹³å‡å€¼å’Œæ–¹å·®
            predictions = []
            
            for i in range(inference_times):
                # å¯¹æ•°æ®æ·»åŠ ä¸€ä¸ªé€æ¸å‡å°‘çš„å™ªå£°
                noise_level = 0.01 * (inference_times - i) / inference_times
                X_noisy = X.copy()
                X_noisy += np.random.normal(0, noise_level, X_noisy.shape)
                
                # è·å–æœ€åä¸€ä¸ªæ ·æœ¬çš„ç´¢å¼•
                last_sample_idx = X_noisy.shape[0] - 1
                
                # è½¬æ¢ä¸ºå¼ é‡å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
                # åˆ†æ‰¹å¤„ç†ä»¥é¿å…è¶…è¿‡æœ€å¤§æ‰¹é‡å¤§å°é™åˆ¶
                batch_size = 32  # æœ€å¤§æ‰¹é‡å¤§å°
                all_outputs = []
                
                # å¤„ç†å®Œæ•´æ‰¹æ¬¡
                for start_idx in range(0, X_noisy.shape[0], batch_size):
                    end_idx = min(start_idx + batch_size, X_noisy.shape[0])
                    batch = X_noisy[start_idx:end_idx]
                    batch_tensor = torch.tensor(batch, dtype=torch.float32).to(self.device)
                    
                    with torch.no_grad():
                        batch_outputs = self.predictor.predict(batch_tensor)
                        all_outputs.append(batch_outputs.cpu().numpy())
                
                # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„è¾“å‡º
                outputs = np.concatenate(all_outputs)
                
                # è·å–æœ€åä¸€å¤©çš„é¢„æµ‹ç»“æœï¼ˆæœ€åä¸€ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼ï¼‰
                prediction = outputs[last_sample_idx] * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                predictions.append(prediction)
            
            # è®¡ç®—å¹³å‡å€¼å’Œæ–¹å·®
            mean_prediction = np.mean(predictions)
            variance = np.var(predictions)
            
            # è¿”å›ç»“æœ
            return {
                "ticker": ticker,
                "mean_prediction": mean_prediction,
                "variance": variance,
                "predictions": predictions,
                "timestamp": timestamp
            }
            
        except Exception as e:
            self.logger.error(f"é¢„æµ‹ {ticker} æ—¶å‡ºé”™: {str(e)}")
            return {"ticker": ticker, "error": str(e)}

    def predict_batch(self, tickers: List[str], inference_times: int = 10) -> List[Dict]:
        """
        æ‰¹é‡é¢„æµ‹å¤šä¸ªè‚¡ç¥¨
        
        Args:
            tickers (List[str]): è‚¡ç¥¨ä»£ç åˆ—è¡¨
            inference_times (int): æ¨ç†æ¬¡æ•°ï¼Œé»˜è®¤ä¸º10
            
        Returns:
            dict: è‚¡ç¥¨ä»£ç åˆ°é¢„æµ‹ç»“æœçš„æ˜ å°„
        """
        results = {}
        for ticker in tickers:
            self.logger.info(f"é¢„æµ‹è‚¡ç¥¨: {ticker}")
            result = self.predict(ticker, inference_times)
            results[ticker] = result
        return results

    def display_results(self, results, batch_mode=False):
        """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
        if batch_mode:
            print("\n" + "="*50)
            print("ğŸš€ æ‰¹é‡è‚¡ç¥¨é¢„æµ‹ç»“æœ")
            print("="*50)
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¢„æµ‹éƒ½å¤±è´¥
            all_failed = True
            result_with_data = None
            
            for ticker, result in results.items():
                if 'error' in result:
                    self.logger.error(f"é¢„æµ‹ {ticker} æ—¶å‡ºé”™: {result['error']}")
                    print(f"\nâŒ {ticker}: é¢„æµ‹å¤±è´¥ - {result['error']}")
                    continue
                else:
                    all_failed = False
                    result_with_data = result
                
                # é¢„æµ‹å€¼ - é™åˆ¶é¢„æµ‹å€¼åœ¨åˆç†èŒƒå›´å†…
                prediction = result['mean_prediction']
                
                # æ£€æŸ¥é¢„æµ‹å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…ï¼Œå¦‚æœè¶…å‡ºåˆ™è­¦å‘Šå¹¶é™åˆ¶
                if abs(prediction) > 10:
                    original_prediction = prediction
                    prediction = max(min(prediction, 10), -10)  # é™åˆ¶åœ¨-10%åˆ°10%ä¹‹é—´
                    self.logger.warning(f"{ticker} åŸå§‹é¢„æµ‹å€¼ {original_prediction:.4f}% è¶…å‡ºåˆç†èŒƒå›´ï¼Œå·²é™åˆ¶ä¸º {prediction:.4f}%")
                
                # è·å–æƒ…æ„Ÿæ–¹å‘
                sentiment = "çœ‹æ¶¨ ğŸ“ˆ" if prediction > 0 else "çœ‹è·Œ ğŸ“‰"
                # è®¡ç®—ä¿¡å¿ƒæ°´å¹³
                abs_pred = abs(prediction)
                if abs_pred < 0.5:
                    confidence = "ä½"
                elif abs_pred < 1.5:
                    confidence = "ä¸­"
                else:
                    confidence = "é«˜"
                
                # è®¡ç®—æ–¹å‘ä¸€è‡´æ€§
                total_predictions = len(result['predictions'])
                positive_count = sum(1 for p in result['predictions'] if p > 0)
                negative_count = total_predictions - positive_count
                
                if positive_count > negative_count:
                    consensus = f"åå¤š ({positive_count}/{total_predictions})"
                elif negative_count > positive_count:
                    consensus = f"åç©º ({negative_count}/{total_predictions})"
                else:
                    consensus = "ä¸­æ€§ (50/50)"
                
                # è®¡ç®—æ ‡å‡†å·®
                std_dev = math.sqrt(result['variance']) if result['variance'] > 0 else 0
                
                # è®¡ç®—95%ç½®ä¿¡åŒºé—´ (åŒæ ·é™åˆ¶åœ¨åˆç†èŒƒå›´å†…)
                lower_bound = max(prediction - 1.96 * std_dev, -10)
                upper_bound = min(prediction + 1.96 * std_dev, 10)
                
                # é¢„æµ‹åŒºé—´
                interval = f"[{lower_bound:.4f}%, {upper_bound:.4f}%]"
                
                # æ˜¾ç¤ºç»“æœ
                print(f"\nğŸ“Š {ticker} | {result['timestamp']}")
                print(f"{'é¢„æµ‹æ–¹å‘:':<12} {sentiment}")
                print(f"{'é¢„æµ‹å€¼:':<12} {prediction:.4f}%")
                print(f"{'ä¿¡å¿ƒæ°´å¹³:':<12} {confidence}")
                print(f"{'é¢„æµ‹åŒºé—´:':<12} {interval}")
                print(f"{'æ³¢åŠ¨ç‡:':<12} {std_dev:.6f}")
                print(f"{'æ–¹å‘ä¸€è‡´æ€§:':<12} {consensus}")
                
                # æ·»åŠ åˆ†éš”çº¿
                print("-"*40)
            
            # æ·»åŠ æ³¨è„š
            if not all_failed and result_with_data:
                print(f"\næ³¨: é¢„æµ‹åŸºäº{len(result_with_data['predictions'])}æ¬¡æ¨ç†è¿è¡Œï¼Œæ•°æ®æ›´æ–°æ—¶é—´ï¼š{result_with_data['timestamp']}")
            elif all_failed:
                print("\nâŒ æ‰€æœ‰è‚¡ç¥¨é¢„æµ‹å‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œæ—¥å¿—ä»¥æ’æŸ¥é—®é¢˜ã€‚")
        else:
            # å•ä¸ªè‚¡ç¥¨é¢„æµ‹ç»“æœå±•ç¤º
            if 'error' in results:
                self.logger.error(f"é¢„æµ‹å¤±è´¥: {results['error']}")
                print(f"\nâŒ é¢„æµ‹å¤±è´¥ - {results['error']}")
                return
                
            # é¢„æµ‹å€¼ - é™åˆ¶é¢„æµ‹å€¼åœ¨åˆç†èŒƒå›´å†…
            prediction = results['mean_prediction']
            
            # æ£€æŸ¥é¢„æµ‹å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…ï¼Œå¦‚æœè¶…å‡ºåˆ™è­¦å‘Šå¹¶é™åˆ¶
            if abs(prediction) > 10:
                original_prediction = prediction
                prediction = max(min(prediction, 10), -10)  # é™åˆ¶åœ¨-10%åˆ°10%ä¹‹é—´
                self.logger.warning(f"{results['ticker']} åŸå§‹é¢„æµ‹å€¼ {original_prediction:.4f}% è¶…å‡ºåˆç†èŒƒå›´ï¼Œå·²é™åˆ¶ä¸º {prediction:.4f}%")
            
            # è·å–æƒ…æ„Ÿæ–¹å‘
            sentiment = "çœ‹æ¶¨ ğŸ“ˆ" if prediction > 0 else "çœ‹è·Œ ğŸ“‰"
            # è®¡ç®—ä¿¡å¿ƒæ°´å¹³
            abs_pred = abs(prediction)
            if abs_pred < 0.5:
                confidence = "ä½"
            elif abs_pred < 1.5:
                confidence = "ä¸­"
            else:
                confidence = "é«˜"
                
            # è®¡ç®—æ–¹å‘ä¸€è‡´æ€§
            total_predictions = len(results['predictions'])
            positive_count = sum(1 for p in results['predictions'] if p > 0)
            negative_count = total_predictions - positive_count
            
            if positive_count > negative_count:
                consensus = f"åå¤š ({positive_count}/{total_predictions})"
            elif negative_count > positive_count:
                consensus = f"åç©º ({negative_count}/{total_predictions})"
            else:
                consensus = "ä¸­æ€§ (50/50)"
                
            # è®¡ç®—æ ‡å‡†å·®
            std_dev = math.sqrt(results['variance']) if results['variance'] > 0 else 0
            
            # è®¡ç®—95%ç½®ä¿¡åŒºé—´ (åŒæ ·é™åˆ¶åœ¨åˆç†èŒƒå›´å†…)
            lower_bound = max(prediction - 1.96 * std_dev, -10)
            upper_bound = min(prediction + 1.96 * std_dev, 10)
            
            # é¢„æµ‹åŒºé—´
            interval = f"[{lower_bound:.4f}%, {upper_bound:.4f}%]"
            
            # æ˜¾ç¤ºç»“æœ
            print("\n" + "="*50)
            print(f"ğŸš€ {results['ticker']} é¢„æµ‹ç»“æœ | {results['timestamp']}")
            print("="*50)
            print(f"{'é¢„æµ‹æ–¹å‘:':<12} {sentiment}")
            print(f"{'é¢„æµ‹å€¼:':<12} {prediction:.4f}%")
            print(f"{'ä¿¡å¿ƒæ°´å¹³:':<12} {confidence}")
            print(f"{'é¢„æµ‹åŒºé—´:':<12} {interval}")
            print(f"{'æ³¢åŠ¨ç‡:':<12} {std_dev:.6f}")
            print(f"{'æ–¹å‘ä¸€è‡´æ€§:':<12} {consensus}")
            
            # æ·»åŠ æ³¨è„š
            print(f"\næ³¨: é¢„æµ‹åŸºäº{len(results['predictions'])}æ¬¡æ¨ç†è¿è¡Œ")

def main(args=None):
    if args is None:
        parser = argparse.ArgumentParser(description="è‚¡ç¥¨ä»·æ ¼é¢„æµ‹")
        parser.add_argument("--ticker", type=str, default=None, help="è‚¡ç¥¨ä»£ç ")
        parser.add_argument("--batch", action="store_true", help="æ‰¹é‡é¢„æµ‹æ¨¡å¼")
        parser.add_argument("--inference-times", type=int, default=10, help="æ¨ç†æ¬¡æ•°")
        args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—æ ¼å¼
    local_logger = logging.getLogger()
    local_logger.setLevel(logging.INFO)
    if not local_logger.handlers:
        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)
        formatter = logging.Formatter('%(message)s')
        ch.setFormatter(formatter)
        local_logger.addHandler(ch)
    
    # æ£€æŸ¥è®¾å¤‡
    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    local_logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹
    model_path = "models/SpaceExploreAI_best.pt"
    local_logger.info(f"åŠ è½½æ¨¡å‹ä¸­: {model_path}")
    
    inferencer = StockPredictor(
        model_path=model_path,
        device=device
    )
    
    # å•åªè‚¡ç¥¨é¢„æµ‹
    if args.ticker:
        ticker = args.ticker
        local_logger.info(f"é¢„æµ‹å•åªè‚¡ç¥¨: {ticker}")
        result = inferencer.predict(ticker, inference_times=args.inference_times)
        inferencer.display_results(result)
    # æ‰¹é‡é¢„æµ‹
    elif args.batch:
        # é»˜è®¤çš„æ‰¹é‡é¢„æµ‹è‚¡ç¥¨åˆ—è¡¨
        tickers = ['QQQ', 'SPY', 'AAPL', 'NVDA', 'TSLA', 'MSFT', 'AMZN', 'GOOG']
        local_logger.info(f"æ‰¹é‡é¢„æµ‹è‚¡ç¥¨: {', '.join(tickers)}")
        results = inferencer.predict_batch(tickers, inference_times=args.inference_times)
        inferencer.display_results(results, batch_mode=True)
    else:
        local_logger.info("è¯·æŒ‡å®šè‚¡ç¥¨ä»£ç æˆ–ä½¿ç”¨--batchå‚æ•°è¿›è¡Œæ‰¹é‡é¢„æµ‹")

if __name__ == "__main__":
    main() 